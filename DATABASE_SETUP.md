# æ•°æ®åº“åˆå§‹åŒ–æ­¥éª¤è¯´æ˜

## å·²é…ç½®çš„æ•°æ®åº“ä¿¡æ¯

- **æ•°æ®åº“åç§°**: JobDetector
- **MongoDBé›†ç¾¤**: blackricemongo.t7k7zg3.mongodb.net
- **è¿æ¥æ–¹å¼**: é€šè¿‡ç¯å¢ƒå˜é‡ï¼ˆ.envæ–‡ä»¶ï¼‰ï¼Œä¸ç¡¬ç¼–ç 

## å°†è¦åˆ›å»ºçš„Collections

ç³»ç»Ÿä¼šè‡ªåŠ¨åˆ›å»ºä»¥ä¸‹5ä¸ªcollectionsï¼š

### 1. companiesï¼ˆå…¬å¸ä¿¡æ¯ï¼‰
**ç”¨é€”**: å­˜å‚¨ç›‘æ§çš„å…¬å¸åˆ—è¡¨å’Œé…ç½®
**å­—æ®µ**:
- name: å…¬å¸åç§°
- domain: å…¬å¸åŸŸåï¼ˆå”¯ä¸€ï¼‰
- careers_url: Careeré¡µé¢URL
- ats_system: ATSç³»ç»Ÿä¿¡æ¯ï¼ˆtype, api_endpointç­‰ï¼‰
- schedule: æŠ“å–è°ƒåº¦é…ç½®
- stats: ç»Ÿè®¡ä¿¡æ¯
- metadata: å…ƒæ•°æ®ï¼ˆè¡Œä¸šã€æ ‡ç­¾ç­‰ï¼‰

**ç´¢å¼•**:
- domain (unique) - ç¡®ä¿å…¬å¸ä¸é‡å¤
- name
- is_active
- metadata.tags

---

### 2. jobsï¼ˆèŒä½ä¿¡æ¯ï¼‰
**ç”¨é€”**: å­˜å‚¨æŠ“å–çš„èŒä½æ•°æ®
**å­—æ®µ**:
- job_id: èŒä½å”¯ä¸€IDï¼ˆå”¯ä¸€ï¼‰
- title: èŒä½æ ‡é¢˜
- company: å…¬å¸åç§°
- location: åœ°ç‚¹
- salary: è–ªèµ„èŒƒå›´
- description: èŒä½æè¿°
- skills: æŠ€èƒ½è¦æ±‚ï¼ˆæ•°ç»„ï¼‰
- source: æ¥æºï¼ˆgreenhouse, leverç­‰ï¼‰
- source_url: åŸå§‹é“¾æ¥ï¼ˆå”¯ä¸€ï¼‰
- posted_date: å‘å¸ƒæ—¥æœŸ
- scraped_at: æŠ“å–æ—¶é—´

**ç´¢å¼•**:
- job_id (unique)
- source_url (unique)
- scraped_at (é™åº)
- company
- location
- skills
- posted_date (é™åº)
- (is_active, scraped_at) å¤åˆç´¢å¼•

---

### 3. user_preferencesï¼ˆç”¨æˆ·åå¥½ï¼‰
**ç”¨é€”**: å­˜å‚¨ç”¨æˆ·çš„èŒä½åŒ¹é…åå¥½ï¼ˆMVPå•ç”¨æˆ·æ¨¡å¼ï¼‰
**å­—æ®µ**:
- user_email: ç”¨æˆ·é‚®ç®±
- keywords: å…³é”®è¯åˆ—è¡¨
- exclude_keywords: æ’é™¤å…³é”®è¯
- locations: åœ°ç‚¹åå¥½
- min_salary: æœ€ä½è–ªèµ„è¦æ±‚
- required_skills: å¿…é¡»æŠ€èƒ½
- preferred_skills: åŠ åˆ†æŠ€èƒ½
- min_match_score: æœ€ä½åŒ¹é…åˆ†æ•°

**é»˜è®¤å€¼**: ç³»ç»Ÿä¼šè‡ªåŠ¨åˆ›å»ºä¸€ä¸ªé»˜è®¤é…ç½®

---

### 4. job_matchesï¼ˆåŒ¹é…ç»“æœï¼‰
**ç”¨é€”**: å­˜å‚¨èŒä½åŒ¹é…è®°å½•
**å­—æ®µ**:
- job_id: å…³è”çš„èŒä½ID
- matched_at: åŒ¹é…æ—¶é—´
- match_score: åŒ¹é…åˆ†æ•°ï¼ˆ0-100ï¼‰
- matched_criteria: åŒ¹é…çš„å…·ä½“æ¡ä»¶
- is_notified: æ˜¯å¦å·²å‘é€é€šçŸ¥
- notified_at: é€šçŸ¥æ—¶é—´

**ç´¢å¼•**:
- job_id
- matched_at (é™åº)
- is_notified

---

### 5. scraper_logsï¼ˆæŠ“å–æ—¥å¿—ï¼‰
**ç”¨é€”**: è®°å½•æ¯æ¬¡æŠ“å–ä»»åŠ¡çš„æ‰§è¡Œæƒ…å†µ
**å­—æ®µ**:
- source: æ•°æ®æºï¼ˆå…¬å¸åï¼‰
- status: çŠ¶æ€ï¼ˆsuccess/failedï¼‰
- jobs_found: å‘ç°çš„èŒä½æ•°
- jobs_new: æ–°å¢èŒä½æ•°
- error_message: é”™è¯¯ä¿¡æ¯
- started_at: å¼€å§‹æ—¶é—´
- completed_at: å®Œæˆæ—¶é—´

**ç´¢å¼•**:
- started_at (é™åº)
- source
- status

---

## æ‰§è¡Œæ­¥éª¤

### å‡†å¤‡å·¥ä½œ
è¯·ç¡®ä¿æ‚¨å·²ç»ï¼š
1. âœ… åœ¨MongoDB Atlasåˆ›å»ºäº†JobDetectoræ•°æ®åº“
2. âœ… .envæ–‡ä»¶å·²é…ç½®å¥½è¿æ¥ä¿¡æ¯

### æ­¥éª¤1: æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ

```bash
cd /Users/tuxy/Codes/TestProjects/JobDetector
source venv/bin/activate
```

### æ­¥éª¤2: è¿è¡Œæ•°æ®åº“åˆå§‹åŒ–è„šæœ¬

```bash
python scripts/init_database.py
```

**è„šæœ¬ä¼šè‡ªåŠ¨æ‰§è¡Œä»¥ä¸‹æ“ä½œ**:
1. è¿æ¥åˆ°MongoDB Atlasçš„JobDetectoræ•°æ®åº“
2. åˆ›å»º5ä¸ªcollectionsï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
3. ä¸ºæ¯ä¸ªcollectionåˆ›å»ºä¼˜åŒ–ç´¢å¼•ï¼ˆå…±15+ä¸ªç´¢å¼•ï¼‰
4. åˆå§‹åŒ–é»˜è®¤ç”¨æˆ·åå¥½é…ç½®
5. éªŒè¯å¹¶æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯

**é¢„æœŸè¾“å‡º**:
```
ğŸš€ Starting database initialization...

ğŸ“¦ Step 1: Creating collections...
âœ… Created collection: companies
âœ… Created collection: jobs
âœ… Created collection: user_preferences
âœ… Created collection: job_matches
âœ… Created collection: scraper_logs

ğŸ“Š Step 2: Creating indexes...
âœ… Created indexes for 'companies' collection
âœ… Created indexes for 'jobs' collection
âœ… Created indexes for 'job_matches' collection
âœ… Created indexes for 'scraper_logs' collection

âš™ï¸  Step 3: Initializing default data...
âœ… Created default user preferences

==================================================
Database Verification
==================================================
Collections (5): companies, jobs, user_preferences, job_matches, scraper_logs
  - companies: 0 documents
  - jobs: 0 documents
  - user_preferences: 1 documents
  - job_matches: 0 documents
  - scraper_logs: 0 documents

Indexes:
  - companies: _id_, domain_1, name_1, is_active_1, metadata.tags_1
  - jobs: _id_, job_id_1, source_url_1, scraped_at_-1, company_1, location_1, skills_1, posted_date_-1, is_active_1_scraped_at_-1
  - job_matches: _id_, job_id_1, matched_at_-1, is_notified_1
  - scraper_logs: _id_, started_at_-1, source_1, status_1
==================================================
âœ… Database initialization completed successfully!

ğŸ‰ Database is ready to use!
```

### æ­¥éª¤3: éªŒè¯è¿æ¥

```bash
python scripts/test_connection.py
```

**é¢„æœŸè¾“å‡º**:
```
âœ… Database connection successful
ğŸ“‹ Collections: ['companies', 'jobs', 'user_preferences', 'job_matches', 'scraper_logs']
ğŸ“Š Companies in database: 0
```

---

## è¿æ¥å®‰å…¨è¯´æ˜

âœ… **å®‰å…¨æªæ–½å·²åˆ°ä½**:
1. **ä¸ç¡¬ç¼–ç **: æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²å­˜å‚¨åœ¨`.env`æ–‡ä»¶ä¸­
2. **Gitå¿½ç•¥**: `.env`æ–‡ä»¶å·²æ·»åŠ åˆ°`.gitignore`ï¼Œä¸ä¼šè¢«æäº¤åˆ°Git
3. **ç¯å¢ƒå˜é‡**: ä»£ç é€šè¿‡`os.getenv()`è¯»å–ï¼Œæ”¯æŒç”Ÿäº§ç¯å¢ƒé…ç½®
4. **æ¨¡æ¿æ–‡ä»¶**: `.env.example`æä¾›é…ç½®æ¨¡æ¿ï¼Œä¸åŒ…å«çœŸå®å¯†ç 

## ä»£ç å·¥ä½œåŸç†

`connection.py`ä¸­çš„è¿æ¥ç®¡ç†å™¨ï¼š
```python
# ä»ç¯å¢ƒå˜é‡è¯»å–ï¼ˆä¸ç¡¬ç¼–ç ï¼‰
mongo_uri = os.getenv('MONGODB_URI')
db_name = os.getenv('MONGODB_DATABASE', 'jobdetector')

# è¿æ¥æ•°æ®åº“
self._client = MongoClient(mongo_uri)
self._db = self._client[db_name]
```

## ä¸‹ä¸€æ­¥

åˆå§‹åŒ–å®Œæˆåï¼Œæ‚¨å¯ä»¥ï¼š
1. å¯¼å…¥50å®¶å…¬å¸æ•°æ®ï¼š`python scripts/import_companies.py`
2. æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯ï¼š`python scripts/import_companies.py --stats`

---

**æ³¨æ„**: å¦‚æœé‡åˆ°é”™è¯¯ï¼Œè¯·æ£€æŸ¥ï¼š
- MongoDB Atlasä¸­IPç™½åå•è®¾ç½®ï¼ˆæ·»åŠ 0.0.0.0/0å…è®¸æ‰€æœ‰IPè®¿é—®ï¼Œä»…æµ‹è¯•ç”¨ï¼‰
- æ•°æ®åº“ç”¨æˆ·æƒé™ï¼ˆç¡®ä¿ç”¨æˆ·æœ‰è¯»å†™æƒé™ï¼‰
- è¿æ¥å­—ç¬¦ä¸²æ ¼å¼æ­£ç¡®
